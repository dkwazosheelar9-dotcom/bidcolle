import pymysql
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import time

# --- æ•°æ®åº“é…ç½® (è¯·ä¿®æ”¹è¿™é‡Œ) ---
DB_CONFIG = {
    'host': '127.0.0.1',
    'port': 3306,
    'user': 'bid',
    'password': '123456',
    'db': 'app_phantasm',
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
}

# --- è¯·æ±‚å¤´é…ç½® ---
DEFAULT_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
    'Accept-Language': 'zh-CN,zh;q=0.9',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}


def get_connection():
    return pymysql.connect(**DB_CONFIG)


def fetch_html(url, referer=None):
    """é€šç”¨æŠ“å–å‡½æ•°"""
    headers = DEFAULT_HEADERS.copy()
    if referer:
        headers['Referer'] = referer

    # è‡ªåŠ¨è®¾ç½® Host
    from urllib.parse import urlparse
    try:
        parsed = urlparse(url)
        headers['Host'] = parsed.netloc
    except:
        pass

    try:
        resp = requests.get(url, headers=headers, timeout=15, verify=False)
        # è‡ªåŠ¨å¤„ç†ç¼–ç 
        if resp.encoding == 'ISO-8859-1':
            resp.encoding = resp.apparent_encoding
        return resp.text
    except Exception as e:
        print(f"   [Error] è¯·æ±‚å¤±è´¥ {url}: {e}")
        return None


def extract_first_detail_link(html, base_url):
    """è‡ªåŠ¨æå–ç¬¬ä¸€ä¸ªçœ‹èµ·æ¥åƒè¯¦æƒ…é¡µçš„é“¾æ¥"""
    soup = BeautifulSoup(html, 'html.parser')
    # ç­–ç•¥ï¼šä¼˜å…ˆæ‰¾ li æ ‡ç­¾ä¸‹çš„ a æ ‡ç­¾ï¼Œä¸”æ–‡æœ¬é•¿åº¦ > 4 çš„
    candidates = soup.select('li a')
    if not candidates:
        candidates = soup.select('tr a')  # è¡¨æ ¼å¸ƒå±€

    for a in candidates:
        href = a.get('href')
        text = a.get_text(strip=True)
        if href and len(text) > 4 and 'javascript' not in href:
            return urljoin(base_url, href)

    # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•é¡µé¢ä»»æ„æ­£æ–‡åŒºåŸŸçš„é•¿é“¾æ¥
    for a in soup.find_all('a'):
        href = a.get('href')
        text = a.get_text(strip=True)
        if href and len(text) > 8 and 'javascript' not in href:
            return urljoin(base_url, href)

    return None


def process_task():
    conn = get_connection()
    try:
        with conn.cursor() as cursor:
            # 1. è·å–å¾…å¤„ç†ä»»åŠ¡
            sql = "SELECT id, url FROM t_static_sample_task WHERE status = 0"
            cursor.execute(sql)
            tasks = cursor.fetchall()

            print(f"ğŸš€ å‘ç° {len(tasks)} ä¸ªå¾…é‡‡é›†ä»»åŠ¡...")

            for task in tasks:
                task_id = task['id']
                list_url = task['url']
                print(f"\n[Task {task_id}] æ­£åœ¨å¤„ç†: {list_url}")

                # 2. æŠ“å–åˆ—è¡¨é¡µ
                list_html = fetch_html(list_url)
                if not list_html:
                    cursor.execute("UPDATE t_static_sample_task SET status = -1 WHERE id = %s", (task_id,))
                    conn.commit()
                    continue

                # 3. è§£æè¯¦æƒ…é¡µé“¾æ¥
                detail_url = extract_first_detail_link(list_html, list_url)
                detail_html = None

                if detail_url:
                    print(f"   -> è‡ªåŠ¨è¯†åˆ«è¯¦æƒ…é¡µ: {detail_url}")
                    # 4. æŠ“å–è¯¦æƒ…é¡µ
                    detail_html = fetch_html(detail_url, referer=list_url)
                else:
                    print("   -> âš ï¸ æœªèƒ½è¯†åˆ«å‡ºè¯¦æƒ…é¡µé“¾æ¥ï¼Œä»…ä¿å­˜åˆ—è¡¨é¡µ")

                # 5. ä¿å­˜å›æ•°æ®åº“
                status = 1 if list_html else -1
                update_sql = """
                    UPDATE t_static_sample_task 
                    SET list_html = %s, detail_url = %s, detail_html = %s, status = %s 
                    WHERE id = %s
                """
                cursor.execute(update_sql, (list_html, detail_url, detail_html, status, task_id))
                conn.commit()
                print(f"   âœ… ä¿å­˜æˆåŠŸï¼")

                time.sleep(1)  # ç¤¼è²Œå»¶æ—¶

    finally:
        conn.close()


if __name__ == "__main__":
    import urllib3

    urllib3.disable_warnings()
    process_task()