# -*- coding: utf-8 -*-
import pymysql
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
import time
import re
import warnings

# å¿½ç•¥ HTTPS è¯ä¹¦è­¦å‘Š
warnings.filterwarnings("ignore")

# --- æ•°æ®åº“é…ç½® ---
DB_CONFIG = {
    'host': '127.0.0.1',
    'port': 3306,
    'user': 'bid',
    'password': '123456',
    'db': 'app_phantasm',
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
}

# --- è¯·æ±‚å¤´é…ç½® ---
DEFAULT_HEADERS = {
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
}


def get_connection():
    return pymysql.connect(**DB_CONFIG)


def fetch_html(url, referer=None):
    headers = DEFAULT_HEADERS.copy()
    if referer:
        headers['Referer'] = referer
    try:
        parsed = urlparse(url)
        headers['Host'] = parsed.netloc
        # verify=False å…³é”®ï¼šé˜²æ­¢éƒ¨åˆ†æ”¿åºœç½‘ç«™è¯ä¹¦è¿‡æœŸæŠ¥é”™
        resp = requests.get(url, headers=headers, timeout=25, verify=False)

        # è‡ªåŠ¨å¤„ç†ä¹±ç 
        if resp.encoding == 'ISO-8859-1':
            resp.encoding = resp.apparent_encoding
        return resp.text
    except Exception as e:
        print(f"   [Error] è¯·æ±‚å¤±è´¥ {url}: {e}")
        return None


def extract_first_detail_link(html, base_url):
    """
    V4.0 ç»ˆæè¯†åˆ«ç®—æ³• (å…¨é¡µæ‰«æ + æƒé‡è¯„åˆ†)
    è§£å†³: ä¹‹å‰ç‰ˆæœ¬å› è¯¯åˆ¤ header åŒºåŸŸè€Œé—æ¼æ­£æ–‡é“¾æ¥çš„é—®é¢˜
    """
    if not html: return None
    soup = BeautifulSoup(html, 'html.parser')

    candidates = []

    # ç­–ç•¥å˜æ›´ï¼šæ‰«æå…¨é¡µæ‰€æœ‰é“¾æ¥ï¼Œä¾é è¯„åˆ†è¿‡æ»¤ï¼Œè€Œä¸æ˜¯é¢„å…ˆç¼©å°èŒƒå›´
    # è¿™æ ·å¯ä»¥é˜²æ­¢å› é¡µé¢å¸ƒå±€å¥‡ç‰¹ï¼ˆå¦‚ phpwebï¼‰å¯¼è‡´çš„æ¼æŠ“
    all_links = soup.find_all('a', href=True)

    for a in all_links:
        href = a['href'].strip()
        text = a.get_text(strip=True)

        # --- A. åŸºç¡€æ¸…æ´— ---
        # æ’é™¤æ— æ•ˆé“¾æ¥
        if not href or href.startswith(('#', 'javascript', 'mailto', 'tel')): continue

        # æ‹¼æ¥ç»å¯¹è·¯å¾„
        full_url = urljoin(base_url, href)

        # æ’é™¤éç½‘é¡µæ–‡ä»¶
        if full_url.lower().endswith(
                ('.pdf', '.doc', '.docx', '.xls', '.xlsx', '.zip', '.rar', '.jpg', '.png', '.css', '.js')):
            continue

        # æ’é™¤è¿‡çŸ­æ–‡æœ¬ (å¦‚ "æ›´å¤š", "GO", "More")
        if len(text) < 4: continue

        # --- B. è¯„åˆ†ç³»ç»Ÿ ---
        score = 0

        # 1. æ ‡é¢˜é•¿åº¦æƒé‡ (æ ‡é¢˜é€šå¸¸è¾ƒé•¿)
        score += len(text) * 0.5

        # 2. ç»“æ„ç‰¹å¾æ¢æµ‹ (è§£å†³æ‚¨çš„ li > div > a é—®é¢˜)
        # åªè¦çˆ¶çº§åŒ…å« title/tit/subjectï¼Œå“ªæ€•æ²¡æœ‰æ—¥æœŸï¼Œä¹Ÿæ˜¯æé«˜æ¦‚ç‡çš„è¯¦æƒ…é¡µ
        parents = list(a.parents)[:4]  # å‘ä¸ŠæŸ¥4å±‚
        is_title_structure = False
        for p in parents:
            p_cls = str(p.get('class', [])).lower()
            p_id = str(p.get('id', '')).lower()
            # æ‚¨çš„æ¡ˆä¾‹å‘½ä¸­ 'title'
            if any(k in p_cls or k in p_id for k in ['title', 'tit', 'subject', 'name', 'bt', 'header', 'link']):
                is_title_structure = True
                break

        if is_title_structure:
            score += 30  # å‘½ä¸­ç»“æ„ç‰¹å¾ï¼ŒåŠ é«˜åˆ†

        # 3. åŒºåŸŸåŠ åˆ† (è½¯æ€§é™åˆ¶)
        # å¦‚æœé“¾æ¥åœ¨ content/list/query è¿™ç§å¤§å®¹å™¨é‡Œï¼ŒåŠ åˆ†
        # è¿™æ¯”ç›´æ¥é™åˆ¶åŒºåŸŸæ›´å®‰å…¨
        top_container = a.find_parent('div', id=re.compile('(content|main|list|query|center|news)', re.I))
        if top_container:
            score += 10

        # 4. åˆ—è¡¨æ ‡ç­¾ç‰¹å¾
        if a.find_parent(['li', 'tr', 'dd']):
            score += 10

        # 5. æ—¥æœŸç‰¹å¾ (è¾…åŠ©)
        if re.search(r'\d{4}[-/å¹´]\d{1,2}', str(a.parent)) or re.search(r'\d{4}[-/å¹´]\d{1,2}', str(a.parent.parent)):
            score += 15

        # 6. é»‘åå•å‡åˆ† (æ’é™¤å¯¼èˆªã€é¡µè„šã€ä¾§æ å¹¿å‘Š)
        # æ‚¨çš„æ¡ˆä¾‹ä¸­æœ‰ sidebar é“¾æ¥å¦‚ "æ‹›æ ‡å…¬å‘Š"ï¼Œé•¿åº¦ä¸º4ï¼Œscore=2
        # è€Œæ­£æ–‡é“¾æ¥é•¿åº¦>20ï¼Œscore>40ï¼Œä¾ç„¶ç¨³èƒœ
        if any(k in text for k in ['é¦–é¡µ', 'ä¸»é¡µ', 'å…³äº', 'è”ç³»', 'æ›´å¤š', 'ä¸‹ä¸€é¡µ', 'ä¸Šä¸€é¡µ', 'å°¾é¡µ', 'ä¸‹è½½', 'æ‹›è˜']):
            score -= 50

        candidates.append((score, full_url))

    if candidates:
        # æŒ‰åˆ†æ•°é™åºæ’åˆ—
        candidates.sort(key=lambda x: x[0], reverse=True)
        best_score, best_link = candidates[0]

        # é˜ˆå€¼åˆ¤æ–­
        if best_score > 10:
            print(f"   -> [æ™ºèƒ½è¯†åˆ«] æœ€ä½³è¯¦æƒ…é¡µ (Score={best_score:.1f}): {best_link}")
            return best_link
        else:
            print(f"   -> [è­¦å‘Š] æœ€é«˜åˆ†ä»…ä¸º {best_score:.1f}ï¼Œæœªè¾¾åˆ°è¯¦æƒ…é¡µæ ‡å‡† (Text: {best_link})")

    return None


def process_task():
    conn = get_connection()
    try:
        with conn.cursor() as cursor:
            # åŒæ ·å¤„ç† status=-1 (å¤±è´¥) çš„ä»»åŠ¡ï¼Œé‡æ–°å°è¯•
            sql = "SELECT id, url FROM t_static_sample_task WHERE status IN (0, -1)"
            cursor.execute(sql)
            tasks = cursor.fetchall()

            print(f"ğŸš€ å‘ç° {len(tasks)} ä¸ªå¾…é‡‡é›†ä»»åŠ¡...")

            for task in tasks:
                task_id = task['id']
                list_url = task['url']
                print(f"\n[Task {task_id}] æ­£åœ¨é‡‡é›†: {list_url}")

                list_html = fetch_html(list_url)
                if not list_html:
                    print("   -> âŒ åˆ—è¡¨é¡µè¯·æ±‚å¤±è´¥")
                    cursor.execute("UPDATE t_static_sample_task SET status = -1 WHERE id = %s", (task_id,))
                    conn.commit()
                    continue

                detail_url = extract_first_detail_link(list_html, list_url)
                detail_html = None

                if detail_url:
                    detail_html = fetch_html(detail_url, referer=list_url)
                    # é‡‡é›†æˆåŠŸï¼Œstatus=1
                    status = 1
                else:
                    print("   -> âš ï¸ æœªèƒ½è¯†åˆ«å‡ºè¯¦æƒ…é¡µé“¾æ¥")
                    # åªæœ‰åˆ—è¡¨é¡µï¼Œstatus=1 ä¹Ÿå¯ä»¥ï¼Œæˆ–è€…ä¿ç•™ -1 è§†æ‚¨ä¸šåŠ¡é€»è¾‘è€Œå®š
                    # è¿™é‡Œè®¾ä¸º 1 å…è®¸åç»­åªç”Ÿæˆåˆ—è¡¨è§„åˆ™
                    status = 1

                update_sql = """
                    UPDATE t_static_sample_task 
                    SET list_html = %s, detail_url = %s, detail_html = %s, status = %s 
                    WHERE id = %s
                """
                cursor.execute(update_sql, (list_html, detail_url, detail_html, status, task_id))
                conn.commit()
                print(f"   âœ… æ ·æœ¬æ•°æ®ä¿å­˜å®Œæ¯•")

                time.sleep(1)

    finally:
        conn.close()


if __name__ == "__main__":
    process_task()